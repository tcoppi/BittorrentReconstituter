\documentclass{acm_proc_article-sp}

\usepackage{url}

\numberofauthors{3}
\author{
  \alignauthor
  Charlie Moore\\
  \email{cmoore@nmt.edu}
  \alignauthor
  Thomas Coppi\\
  \email{tcoppi@nmt.edu}
  \alignauthor
  Aaron Lovato\\
  \email{alovato@nmt.edu}
}
\title{BitTorrent Reconstitutor Project Final Report}

\begin{document}
\maketitle
\begin{abstract}
This paper describes the BitTorrent Reconstitutor project. Specifically, it
contains an overview of the BitTorrent protocol and how our project aims to
improve the state of network forensics on this front.  \end{abstract}
%\keywords{}

\section{Introduction}
The BitTorrent Reconstitutor identifies BitTorrent file transfers in network
traffic and extracts the original file.  We assume that a comprehensive packet
capture has been performed.  We decode the traffic according to the official
BitTorrent specification~\cite{officialspec} and ignore any extensions to the
protocol for now; they are left for future work.

\section{Short overview of the BitTorrent Protocol}
BitTorrent is a protocol
designed for efficient transfer of both large and small files over the
Internet. In order to achieve this, BitTorrent uses a novel technique in which
it breaks down the file to be transferred into many uniform \emph{pieces}.
These \emph{pieces} are then distributed amongst the \emph{peers} (clients
downloading the file) in such a way that each \emph{peer} chooses the next
piece to download based on which one it can download fastest from the set of
peers, not necessarily the next one in sequential order.  One common strategy
of downloading pieces is rarest first~\cite{availability}.  This strategy is
optimal because as more peers acquire the rare pieces, the less rare it
becomes, enabling other peers to download those pieces at a faster rate than
before.  The peers discover each other through a centralized tracker service
that each peer can query to see the status of other peers and how to connect to
them.  This method of transferring files in pieces gives it the property that
it is impossible to recover the original file or determine if a file was
actually downloaded or uploaded in whole just from a straightforward
examination of the network traffic.

\section{Problem Addressed}
Prior to this project, there was not a publicly available tool that network
forensics analysts could use to extract files transferred over BitTorrent.
However, such tools do exist for other file transfer protocols (such as
\texttt{tcpxtract} \footnote{\url{http://tcpxtract.sourceforge.net}}). This
tool extends the capability of the analyst to extract files from network
traffic to include the BitTorrent protocol. This gap in capabilities was deemed
to be particularly interesting because manually recovering a file transferred
over BitTorrent from network traffic would be impractical due to the variable
number of peers and the fragmentation of files into pieces that are transferred
out of order.

\section{Threat Model}
One of the ways of breaking up threats is by categorizing them into two groups:
inbound and outbound threats.  Outbound threats consist primarily of data
exfiltration problems.  Inbound attacks focus on malware and contraband. Both
inbound and outbound threats can fall under the umbrella of policy enforcement.

\subsection{Threats}
Threats that this application can mitigate include, but are not limited to,
transfer of contraband using BitTorrent, analysis of network traffic from an
incident in which BitTorrent was used to transfer files to a compromised host,
and detection of data exfiltration where BitTorrent is used to break the
file(s) into smaller pieces that may evade detection from file scanning
utilities. Note that in the case of exfiltration, the application would run
against live traffic, while the transfer of contraband and files to a
compromised host would require offline processing of packet capture files.


\subsection{Use Cases}
The main motivation for this project is to give an analyst investigating an
incident involving BitTorrent a tool to identify the role BitTorrent played.  An
example of such a situation would be an investigation searching for child
pornography transferred across a network. Without a tool of this sort, analysts
would have to manually reconstruct the files and do so in such a way as to not
compromise their admissibility in court. Furthermore, the analyst would have to
ensure that all parts were received by the computer in question. We attempt to
verify the successful download of all parts of the file in order to verify the
integrity of the data our tool produces.

Another situation in which this tool will be useful occurs when malware is
downloaded to a compromised computer using BitTorrent. If the attackers clean up
the compromised computer before a disk image is taken, network traffic provides
the only source of a sample of the malware used. Retrieving this file or files
from the network would be useful for further mitigation of the attack. Also,
identifying the peers involved in the download would allow action to be taken to
prevent them from being used in further attacks. To this end, our tool also
lists all IP addresses involved in the transfer of each file.

One last use case is to mitigate exfiltration of data.  If a user is
using the BitTorrent protocol to send data out of the network, the network
adminstrators would like to know.  This can be accomplished by inspecting the
files that we extract, and possibly ensuring that the headers don't contain
sensitive information, either.  This would require the use of a live capture stream.


\section{Approach}
We started this project by extensively reviewing the BitTorrent protocol
specification~\cite{officialspec}.  Based on our own experiences as well as
comments from our proposal presentation, we found that many clients use
unofficial extensions to the protocol, such as using UDP instead of TCP. In
light of the fact that reviewing and supporting the many different
implementations would require a much greater amount of time than our project
would allow, we decided to use the official specification to decode
traffic. Extending our project in the future to handle unofficial
implementations would entail replacing or modifying a module based on the
specific extension desired. Such modifications are made feasible by splitting
our code into three modules: a packet handler, a BitTorrent session identifier,
and a file reconstructor.

\subsection{Packet Handler}
The Packet Handler performs the initial decoding of network packets up to the
transport layer. Since the official specification states that BitTorrent runs
over TCP, this module is built specifically to decode TCP/IP packets. It
produces a data structure that contains information needed to identify
BitTorrent sessions. Each of these data structures is written to a pipe for
concurrent processing by the next module. The main purpose of modularizing this
part of the code is to allow future extensions to support implementations of the
BitTorrent protocol that use a different transport layer protocol (e.g., UDP
instead of TCP). Building in a different module for UDP that produces the same
output would allow the rest of the code to operate as it is currently designed
without consideration of the underlying protocol.

\subsection{Session Finder}
The Session Finder module reads in the packet data structures from the packet
handler and parses them to identify BitTorrent sessions. A BitTorrent session is
defined by a tracker request for one or more files, the response, the pieces in
the actual file(s), and the tracker request stating that the download has
completed. When a "starting" request and corresponding response is found, the
session finder attempts to parse any non-tracker related packets into BitTorrent
pieces. If a packet is not a piece message, it will be discarded. Otherwise, the
session finder will either add a new piece to the corresponding session or add
the data to an unfinished piece. Once the "completed" tracker request is found,
the session is considered complete and is then written to a pipe for
processing. Incomplete sessions will not be processed because we cannot be sure
that the data in the session is meaningful until it is complete. The session
finder terminates when the packet handler closes the input pipe and all packets
have been processed.

\subsection{File Reconstructor}
The File Reconstructor module takes in BitTorrent sessions created by the
Session Finder module and uses the pieces in the session to reconstruct the
original file. It does this using the information each piece has, such as the
number of the major piece it is contained within and the offset within this
major piece. With this, the reconstructor can rebuild the major pieces that the
files were originally broken up into, separate out a transfer that has multiple
logical files, verify the piece SHA-1 hashes, and use them to piece together
the original file. Separation of multiple files and verification of the hashes
both require that the original \texttt{.torrent} file is specified.

\subsection{Putting It All Together}
We designed the system to run the modules concurrently, using pipes to
communicate with each other, for several reasons. The main motivation was to be
able to handle live input because sequential execution of the modules would not
be possible if the packet handler never exited. Since the packet handler would
never terminate when run with a live input, all of the modules need to be run in
parallel. Accordingly, the driver for the application sets up pipes and creates
3 processes to run each of the modules. Each module will block until its pipes
are opened by another module. The driver performs several other tasks including
parsing input options and cleanup of the pipes, but all of the major processing
is contained in the 3 modules it runs.

\subsection{Challenges Encountered}
The first challenge in this project came from the wide variety of unofficial
extensions to the BitTorrent protocol used by various clients. As mentioned
above, our solution to this problem is to handle traffic according to the
official specification and design our code in a way that allows future
improvements to support new extensions to the protocol without redesigning the
whole project.  In addition, not all clients create \texttt{.torrent} files the
same way.  Some clients add fields that aren't specified in the specification,
such as ``title'' and ``locale'', which required discovery and additional
parsing machinery.

The next challenge we faced was discovered while designing the project.
Initially, we were planning to run each module successively to ensure all parts
of the input file had been processed by one module before the next module
started running. However, this design would have made working with a live input
nearly impossible and thus we worked on an alternate design, which led to the
concurrent processing with multiple processes connected using pipes that we
finally settled on and used in our implementation.

The last major challenge was discovering things that TCP was doing a lot of
things that we didn't expect, such as packing BitTorrent PDU's together and not
just starting on protocol boundaries.  This led to a substantial amount of time
debugging until we finally figured out what was going on and implemented a fix.

\section{Deliverables}
Our deliverable mainly consists of the source code to our application, a
Makefile to build the code, and a README. It also contains a set of sample data
to run the application against to demonstrate its operation.

\subsection{Functionality}
The application identifies and reconstructs any files transferred using the
BitTorrent protocol from network traffic. It can be run against both live input
and stored packet capture (pcap) files. It takes as input either a network
interface (for live input) or a pcap file and a list of \texttt{.torrent}
files. The \texttt{.torrent} files are necessary for verification of files found
in the network traffic; however, all files will be reconstructed, not just those
that can be verified. The application produces the files as output along with
data pertaining to the transfer of the files as well as whether each file was
verified.

Specifically, this application performs the following tasks: identifies files,
reconstructs them, logs information about the file transfer, and verifies the
integrity of the file based on a \texttt{.torrent} file (if provided). It does
not perform any processing or analysis of the files other than that which is
necessary for identification and reconstruction of the files. Other applications
and/or manual analysis will be needed to process the files separately from this
application.

\subsection{Proposal Deviations}
A major deviation from the proposal is that we discovered that the
\texttt{.torrent} file will be required if more than one file is being
transferred at once.  This is because the files are just just added
sequentially to pieces, the pieces can be broken up anywhere.  The way
BitTorrent gets around this is to put the file lengths in the \texttt{.torrent}
so the client knows where to break up the monolithic file that it receives.
The way we resolve this if the \texttt{.torrent} isn't available is to output
the monolithic file and let the user figure out the boundaries manually, or use
a file carving utility such as scalpel\cite{scalpel}.

\section{Team Members}
The three team members on this project all contributed to the whole codebase
roughly equally. Notable contributions from each team member are listed below.

\subsection{Aaron Lovato}
Aaron developed the Packet Handler module, wrote most of the code to decode
\texttt{.torrent} files, developed the Piece message decoding system, and
contributed a substantial amount of the data structures used in the system. He
also performed manual protocol decoding and packet tracing to aid in debugging
the the Session Finder module. Aside from working on the codebase, Aaron also
handled organizing group meetings and initial assignment of modules to the other
group members.

\subsection{Charlie Moore}
Charlie developed the driver for the project, performed a large amount of code
cleanup, developed the data structure representing \texttt{.torrent} files,
contributed a substantial amount of work to the File Reconstructor, and updated
the API used in the project multiple times.

\subsection{Thomas Coppi}
Thomas contributed most of the Session Finder and a large part of the Session
and File Reconstructor modules, developed the data structures used to represent
files, and implemented SHA-1 verification of individual pieces of the file
transferred.  He also set up the test environment and gathered initial test
data.

\section{Forensics Impact}
This application will give analysts the ability to extract files transferred
using BitTorrent from network traffic. While tools (such as virus scanners) and
techniques (such as reverse engineering) are currently available and used to
analyze files, no publicly available application exists to reconstruct files
transferred over the BitTorrent protocol. This application is designed simply to
fill the gap in retrieving capabilities rather than extending any analysis
capability.

As noted in the threat model, most uses for this application will result in
processing of offline data. Accordingly, the main context for usage of this
application will be post-incident analysis, after packets captures have been
collected. However, some uses in which the application is processing live input
can be used to initially identify an incident rather than respond to a known
incident.

\subsection{Future}
As a possible future extension, Distributed Hash Table (DHT) is close to
becoming standardized and is currently in use by many big BitTorrent clients.
DHT allows for every peer to be a tracker, so centralized tracker services are
not needed to get the peer and metadata information~\cite{dhtext}. Torrent files
can be distributed through DHT, which has a big impact on the practical
usefulness of our program.  Specifically, it would be possible to sniff the
\texttt{.torrent} along with the other BitTorrent traffic, which means that we
could more consistently do verification and file separation. As of now, the
\texttt{.torrent} file has to be captured through some external means if a full
extraction and verification is needed.  If we can incorporate DHT technology
into our program, we can eliminate this constraint.

Another extension to the BitTorrent protocol that has become popular is protocol
encryption.  This encapsulates BitTorrent protocol traffic in relatively weak
RC-4 encryption as a way to get around some protocol shapers that detect
BitTorrent traffic and throttle it slower as a way to reduce load on the
network. This complicates matters because it prevents us from reading both the
BitTorrent protocol header and the payload. The keys for encryption are
exchanged using Diffie-Hellman, and as we are a passive observer, we have no way
to obtain the key.  If it were possible to obtain the key used, such as by using
traditional host forensics, decrypting the stream would be a simple addition to
the Session Finder's packet decoding.

\section{Conclusion}
In conclusion, this application solves the problem of being unable to extract
files encapsulated in the standard BitTorrent protocol from network traffic.  A
company or analyst would need this program for the use cases described above.
No publicly available tool currently provides this functionality, so it fills a
hole in the network forensics analyst's toolkit.

\nocite{*}
\bibliographystyle{plain}
\bibliography{finalrefs}

\end{document}
